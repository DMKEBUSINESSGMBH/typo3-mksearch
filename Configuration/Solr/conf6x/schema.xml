<?xml version="1.0" encoding="UTF-8" ?>
<!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor
    license agreements. See the NOTICE file distributed with this work for additional
    information regarding copyright ownership. The ASF licenses this file to
    You under the Apache License, Version 2.0 (the "License"); you may not use
    this file except in compliance with the License. You may obtain a copy of
    the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required
    by applicable law or agreed to in writing, software distributed under the
    License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS
    OF ANY KIND, either express or implied. See the License for the specific
    language governing permissions and limitations under the License. -->

<!-- This is the Solr schema file. This file should be named "schema.xml"
    and should be in the conf directory under the solr home (i.e. ./solr/conf/schema.xml
    by default) or located where the classloader for the Solr webapp can find
    it. This example schema is the recommended starting point for users. It should
    be kept correct and concise, usable out-of-the-box. For more information,
    on how to customize this file, please see http://wiki.apache.org/solr/SchemaXml
    PERFORMANCE NOTE: this schema includes many optional features and should
    not be used for benchmarking. To improve performance one could - set stored="false"
    for all fields possible (esp large fields) when you only need to search on
    the field but don't need to return the original value. - set indexed="false"
    if you don't need to search on the field, but only return the field as a
    result of searching on other indexed fields. - remove all unneeded copyField
    statements - for best index size and searching performance, set "index" to
    false for all general text fields, use copyField to copy them to the catchall
    "text" field, and use that for searching. - For maximum indexing performance,
    use the StreamingUpdateSolrServer java client. - Remember to run the JVM
    in server mode, and use a higher logging level that avoids logging every
    request -->


<!--
    die Version sollte entfernt werden wenn diese Schema als Vorlage dient fÃ¼r neuere Solr Version (>= 4.6.x).
    In diesem schema sollte es aber bleiben da die Unit Tests mit Solr 4.0 laufen und dort kommt die folgende
    Fehlermeldung:
    org.apache.solr.common.SolrException:org.apache.solr.common.SolrException: uniqueKey field (null) can not be configured to be multivalued
-->
<schema name="mksearch" version="1.2">
    <!-- attribute "name" is the name of this schema and is only used for display
        purposes. Applications should change this to reflect the nature of the search
        collection. version="1.2" is Solr's version number for the schema syntax
        and semantics. It should not normally be changed by applications. 1.0: multiValued
        attribute did not exist, all fields are multiValued by nature 1.1: multiValued
        attribute introduced, false by default 1.2: omitTermFreqAndPositions attribute
        introduced, true by default except for text fields. -->

    <types>
        <!-- field type definitions. The "name" attribute is just a label to be
            used by field definitions. The "class" attribute and any other attributes
            determine the real behavior of the fieldType. Class names starting with "solr"
            refer to java classes in the org.apache.solr.analysis package. -->

        <!-- The StrField type is not analyzed, but indexed/stored verbatim. It
            supports doc values but in that case the field needs to be single-valued
            and either required or have a default value.
            Use this for case sensitive search or only stored fields
            -->
        <fieldType name="string" class="solr.StrField"
            sortMissingLast="true" docValues="true" />
        <fieldType name="strings" class="solr.StrField"
            sortMissingLast="true" multiValued="true" docValues="true" />



        <!-- The StrField type is not analyzed,
            so we use TextField to add lowercase filters.
            -->
        <fieldType name="string_ci" class="solr.TextField"
            sortMissingLast="true" omitNorms="true"
        >
            <analyzer>
                <tokenizer class="solr.KeywordTokenizerFactory" />
                <filter class="solr.LowerCaseFilterFactory"/>
            </analyzer>
        </fieldType>

        <fieldType name="strings_ci" class="solr.TextField"
            sortMissingLast="true" multiValued="true"
            omitNorms="true"
        >
            <analyzer>
                <tokenizer class="solr.KeywordTokenizerFactory" />
                <filter class="solr.LowerCaseFilterFactory"/>
            </analyzer>
        </fieldType>

        <!-- boolean type: "true" or "false" -->
        <fieldType name="boolean" class="solr.BoolField"
            sortMissingLast="true" />

        <fieldType name="booleans" class="solr.BoolField"
            sortMissingLast="true" multiValued="true" />

        <!-- sortMissingLast and sortMissingFirst attributes are optional attributes
            are currently supported on types that are sorted internally as strings and
            on numeric types. This includes "string","boolean", and, as of 3.5 (and 4.x),
            int, float, long, date, double, including the "Trie" variants. - If sortMissingLast="true",
            then a sort on this field will cause documents without the field to come
            after documents with the field, regardless of the requested sort order (asc
            or desc). - If sortMissingFirst="true", then a sort on this field will cause
            documents without the field to come before documents with the field, regardless
            of the requested sort order. - If sortMissingLast="false" and sortMissingFirst="false"
            (the default), then default lucene sorting will be used which places docs
            without the field first in an ascending sort and last in a descending sort. -->

        <!-- Default numeric field types. For faster range queries, consider the
            tint/tfloat/tlong/tdouble types. These fields support doc values, but they
            require the field to be single-valued and either be required or have a default
            value. -->
        <fieldType name="int" class="solr.TrieIntField" docValues="true"
            precisionStep="0" positionIncrementGap="0" />
        <fieldType name="float" class="solr.TrieFloatField"
            docValues="true" precisionStep="0" positionIncrementGap="0" />
        <fieldType name="long" class="solr.TrieLongField" docValues="true"
            precisionStep="0" positionIncrementGap="0" />
        <fieldType name="double" class="solr.TrieDoubleField"
            docValues="true" precisionStep="0" positionIncrementGap="0" />

        <fieldType name="ints" class="solr.TrieIntField" docValues="true"
            precisionStep="0" positionIncrementGap="0" multiValued="true" />
        <fieldType name="floats" class="solr.TrieFloatField"
            docValues="true" precisionStep="0" positionIncrementGap="0"
            multiValued="true" />
        <fieldType name="longs" class="solr.TrieLongField" docValues="true"
            precisionStep="0" positionIncrementGap="0" multiValued="true" />
        <fieldType name="doubles" class="solr.TrieDoubleField"
            docValues="true" precisionStep="0" positionIncrementGap="0"
            multiValued="true" />

        <!-- Numeric field types that index each value at various levels of precision
            to accelerate range queries when the number of values between the range endpoints
            is large. See the javadoc for NumericRangeQuery for internal implementation
            details. Smaller precisionStep values (specified in bits) will lead to more
            tokens indexed per value, slightly larger index size, and faster range queries.
            A precisionStep of 0 disables indexing at different precision levels. -->
        <fieldType name="tint" class="solr.TrieIntField" docValues="true"
            precisionStep="8" positionIncrementGap="0" />
        <fieldType name="tfloat" class="solr.TrieFloatField"
            docValues="true" precisionStep="8" positionIncrementGap="0" />
        <fieldType name="tlong" class="solr.TrieLongField" docValues="true"
            precisionStep="8" positionIncrementGap="0" />
        <fieldType name="tdouble" class="solr.TrieDoubleField"
            docValues="true" precisionStep="8" positionIncrementGap="0" />

        <fieldType name="tints" class="solr.TrieIntField" docValues="true"
            precisionStep="8" positionIncrementGap="0" multiValued="true" />
        <fieldType name="tfloats" class="solr.TrieFloatField"
            docValues="true" precisionStep="8" positionIncrementGap="0"
            multiValued="true" />
        <fieldType name="tlongs" class="solr.TrieLongField"
            docValues="true" precisionStep="8" positionIncrementGap="0"
            multiValued="true" />
        <fieldType name="tdoubles" class="solr.TrieDoubleField"
            docValues="true" precisionStep="8" positionIncrementGap="0"
            multiValued="true" />

        <!-- The format for this date field is of the form 1995-12-31T23:59:59Z,
            and is a more restricted form of the canonical representation of dateTime
            http://www.w3.org/TR/xmlschema-2/#dateTime The trailing "Z" designates UTC
            time and is mandatory. Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
            All other components are mandatory. Expressions can also be used to denote
            calculations that should be performed relative to "NOW" to determine the
            value, ie... NOW/HOUR ... Round to the start of the current hour NOW-1DAY
            ... Exactly 1 day prior to now NOW/DAY+6MONTHS+3DAYS ... 6 months and 3 days
            in the future from the start of the current day Consult the TrieDateField
            javadocs for more information. Note: For faster range queries, consider the
            tdate type -->
        <fieldType name="date" class="solr.TrieDateField" docValues="true"
            precisionStep="0" positionIncrementGap="0" />
        <fieldType name="dates" class="solr.TrieDateField" docValues="true"
            precisionStep="0" positionIncrementGap="0" multiValued="true" />

        <!-- A Trie based date field for faster date range queries and date faceting. -->
        <fieldType name="tdate" class="solr.TrieDateField" docValues="true"
            precisionStep="6" positionIncrementGap="0" />

        <fieldType name="tdates" class="solr.TrieDateField"
            docValues="true" precisionStep="6" positionIncrementGap="0"
            multiValued="true" />


        <!--Binary data type. The data should be sent/retrieved in as Base64 encoded
            Strings -->
        <fieldType name="binary" class="solr.BinaryField" />

        <!-- The "RandomSortField" is not used to store or search any data. You
            can declare fields of this type it in your schema to generate pseudo-random
            orderings of your docs for sorting or function purposes. The ordering is
            generated based on the field name and the version of the index. As long as
            the index version remains unchanged, and the same field name is reused, the
            ordering of the docs will be consistent. If you want different psuedo-random
            orderings of documents, for the same version of the index, use a dynamicField
            and change the field name in the request. -->
        <fieldType name="random" class="solr.RandomSortField" indexed="true" />

        <!--
            For Geospatial search
        -->
        <fieldType name="location" class="solr.LatLonType" subFieldSuffix="_coord" />

        <!-- solr.TextField allows the specification of custom text analyzers specified
            as a tokenizer and a list of token filters. Different analyzers may be specified
            for indexing and querying. The optional positionIncrementGap puts space between
            multiple fields of this type on the same document, with the purpose of preventing
            false phrase matching across fields. For more info on customizing your analyzer
            chain, please see http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters -->

        <!-- One can also specify an existing Analyzer class that has a default
            constructor via the class attribute on the analyzer element <fieldType name="text_greek"
            class="solr.TextField"> <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
            </fieldType> -->

        <!-- A text field that only splits on whitespace for exact matching of words -->
        <fieldType name="text_ws" class="solr.TextField"
            positionIncrementGap="100">
            <analyzer>
                <tokenizer class="solr.WhitespaceTokenizerFactory" />
                <filter class="solr.LowerCaseFilterFactory"/>
            </analyzer>
        </fieldType>


        <!--
            the same as full_text but without synonyms. can be used for example for highlighting
        -->
        <fieldType name="text" class="solr.TextField"
            positionIncrementGap="100">
            <analyzer type="index">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1"
                    generateNumberParts="1"
                    catenateWords="1"
                    catenateNumbers="1"
                    catenateAll="0"
                    splitOnCaseChange="1"
                    preserveOriginal="1"
                />
                <filter class="solr.LowerCaseFilterFactory"/>
                <filter class="solr.GermanNormalizationFilterFactory"/>
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
            <analyzer type="query">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1"
                    generateNumberParts="1"
                    catenateWords="0"
                    catenateNumbers="0"
                    catenateAll="0"
                    splitOnCaseChange="1"
                    preserveOriginal="1"
                />
                <filter class="solr.LowerCaseFilterFactory"/>
                <filter class="solr.GermanNormalizationFilterFactory"/>
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
        </fieldType>

        <fieldType name="text_german" class="solr.TextField"
            positionIncrementGap="100">
            <analyzer type="index">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>

                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1"
                    generateNumberParts="1"
                    catenateWords="1"
                    catenateNumbers="1"
                    catenateAll="0"
                    splitOnCaseChange="1"
                    preserveOriginal="1"
                />

                <filter class="solr.LowerCaseFilterFactory"/>

                <!--
                    minWordSize : only words longer than this get processed
                    minSubwordSize : only subwords longer than this get to the output stream
                    maxSubwordSize : only subwords shorter than this get to the output stream
                    onlyLongestMatch : add only the longest matching subword to the stream
                -->
                <filter class="solr.DictionaryCompoundWordTokenFilterFactory"
                    dictionary="lang/dictionary_de.txt"
                    minWordSize="5"
                    minSubwordSize="3"
                    maxSubwordSize="30"
                    onlyLongestMatch="false"
                />
                <!-- Case insensitive stop word removal.
                    add enablePositionIncrements=true in both the index and query
                    analyzers to leave a 'gap' for more accurate phrase queries.
                -->
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.GermanNormalizationFilterFactory"/>
                <filter class="solr.SnowballPorterFilterFactory" language="German2" protected="lang/protwords_de.txt"/>
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
            <analyzer type="query">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>

                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1"
                    generateNumberParts="1"
                    catenateWords="0"
                    catenateNumbers="0"
                    catenateAll="0"
                    splitOnCaseChange="1"
                    preserveOriginal="1"
                />
                <filter class="solr.LowerCaseFilterFactory"/>
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.GermanNormalizationFilterFactory"/>
                <filter class="solr.SnowballPorterFilterFactory" language="German2" protected="lang/protwords_de.txt"/>
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
        </fieldType>

        <fieldType name="text_english" class="solr.TextField"
            positionIncrementGap="100">
            <analyzer type="index">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1"
                    generateNumberParts="1"
                    catenateWords="1"
                    catenateNumbers="1"
                    catenateAll="0"
                    splitOnCaseChange="1"
                    preserveOriginal="1"
                />
                <filter class="solr.LowerCaseFilterFactory"/>

                <!--
                    minWordSize : only words longer than this get processed
                    minSubwordSize : only subwords longer than this get to the output stream
                    maxSubwordSize : only subwords shorter than this get to the output stream
                    onlyLongestMatch : add only the longest matching subword to the stream
                -->
                <filter class="solr.DictionaryCompoundWordTokenFilterFactory"
                    dictionary="lang/dictionary_en.txt"
                    minWordSize="5"
                    minSubwordSize="3"
                    maxSubwordSize="30"
                    onlyLongestMatch="false"
                />
                <!-- Case insensitive stop word removal.
                    add enablePositionIncrements=true in both the index and query
                    analyzers to leave a 'gap' for more accurate phrase queries.
                -->
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_en.txt" format="snowball" />
                <filter class="solr.GermanNormalizationFilterFactory"/>
                <filter class="solr.SnowballPorterFilterFactory" language="English" protected="lang/protwords_en.txt"/>
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
            <analyzer type="query">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1"
                    generateNumberParts="1"
                    catenateWords="0"
                    catenateNumbers="0"
                    catenateAll="0"
                    splitOnCaseChange="1"
                    preserveOriginal="1"
                />
                <filter class="solr.LowerCaseFilterFactory"/>
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_en.txt" format="snowball" />
                <filter class="solr.GermanNormalizationFilterFactory"/>
                <filter class="solr.SnowballPorterFilterFactory" language="English" protected="lang/protwords_en.txt"/>
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
        </fieldType>

        <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
            words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
            so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
            Synonyms and stopwords are customized by external files, and stemming is enabled.
            Duplicate tokens at the same position (which may result from Stemmed Synonyms or
            WordDelim parts) are removed.
            -->
        <fieldType name="full_text_german" class="solr.TextField" positionIncrementGap="100">
            <analyzer type="index">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>

                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1"
                    generateNumberParts="1"
                    catenateWords="1"
                    catenateNumbers="1"
                    catenateAll="0"
                    splitOnCaseChange="1"
                    preserveOriginal="1"
                />

                <filter class="solr.LowerCaseFilterFactory"/>

                <!-- best practice (currently) for synonyms is to add them by
                    expansions during index time
                    solr.KeywordTokenizerFactory as tokenizerFactory
                    so synonyms with whitespaces are treated as phrase
                -->
                <filter
                    class="solr.SynonymFilterFactory"
                    synonyms="lang/synonyms_de.txt"
                    ignoreCase="true"
                    expand="true"
                    tokenizerFactory="solr.KeywordTokenizerFactory"
                />

                <!--
                    minWordSize : only words longer than this get processed
                    minSubwordSize : only subwords longer than this get to the output stream
                    maxSubwordSize : only subwords shorter than this get to the output stream
                    onlyLongestMatch : add only the longest matching subword to the stream
                    used to split words, containing of several words into the partial words
                    e.g. get donau, dampf, schiff, fahrt from donaudampfschifffahrt to have results
                    containing donaudampfschifffahrt when searching after schiff
                -->
                <filter class="solr.DictionaryCompoundWordTokenFilterFactory"
                    dictionary="lang/dictionary_de.txt"
                    minWordSize="5"
                    minSubwordSize="3"
                    maxSubwordSize="30"
                    onlyLongestMatch="false"
                />

                <!-- Case insensitive stop word removal.
                    add enablePositionIncrements=true in both the index and query
                    analyzers to leave a 'gap' for more accurate phrase queries.
                -->
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.GermanNormalizationFilterFactory"/>
                <filter class="solr.SnowballPorterFilterFactory" language="German2" protected="lang/protwords_de.txt"/>
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
            <analyzer type="query">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>

                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1"
                    generateNumberParts="1"
                    catenateWords="0"
                    catenateNumbers="0"
                    catenateAll="0"
                    splitOnCaseChange="1"
                    preserveOriginal="1"
                />
                <filter class="solr.LowerCaseFilterFactory"/>
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.GermanNormalizationFilterFactory"/>
                <filter class="solr.SnowballPorterFilterFactory" language="German2" protected="lang/protwords_de.txt"/>
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
        </fieldType>
        <fieldType name="full_text_english" class="solr.TextField" positionIncrementGap="100">
            <analyzer type="index">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1"
                    generateNumberParts="1"
                    catenateWords="1"
                    catenateNumbers="1"
                    catenateAll="0"
                    splitOnCaseChange="1"
                    preserveOriginal="1"
                />
                <filter class="solr.LowerCaseFilterFactory"/>
                <filter
                    class="solr.SynonymFilterFactory"
                    synonyms="lang/synonyms_en.txt"
                    ignoreCase="true"
                    expand="true"
                    tokenizerFactory="solr.KeywordTokenizerFactory"
                />
                <filter class="solr.DictionaryCompoundWordTokenFilterFactory"
                    dictionary="lang/dictionary_en.txt"
                    minWordSize="5"
                    minSubwordSize="3"
                    maxSubwordSize="30"
                    onlyLongestMatch="false"
                />
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_en.txt" format="snowball" />
                <filter class="solr.GermanNormalizationFilterFactory"/>
                <filter class="solr.SnowballPorterFilterFactory" language="English" protected="lang/protwords_en.txt"/>
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
            <analyzer type="query">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1"
                    generateNumberParts="1"
                    catenateWords="0"
                    catenateNumbers="0"
                    catenateAll="0"
                    splitOnCaseChange="1"
                    preserveOriginal="1"
                />
                <filter class="solr.LowerCaseFilterFactory"/>
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_en.txt" format="snowball" />
                <filter class="solr.GermanNormalizationFilterFactory"/>
                <filter class="solr.SnowballPorterFilterFactory" language="English" protected="lang/protwords_en.txt"/>
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
        </fieldType>

        <!-- Less flexible matching, but less false matches. Probably not ideal
            for product names, but may be good for SKUs. Can insert dashes in the wrong
            place and still match. -->
        <fieldType name="textTight" class="solr.TextField"
            positionIncrementGap="100">
            <analyzer>
                <tokenizer class="solr.WhitespaceTokenizerFactory" />
                <!-- best practice (currently) for synonyms is to add them by
                    expansions during index time
                    solr.KeywordTokenizerFactory as tokenizerFactory
                    so synonyms with whitespaces are treated as phrase
                -->
                <filter
                    class="solr.SynonymFilterFactory"
                    synonyms="lang/synonyms_de.txt"
                    ignoreCase="true"
                    expand="false"
                    tokenizerFactory="solr.KeywordTokenizerFactory"
                />
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="0" generateNumberParts="0" catenateWords="1"
                    catenateNumbers="1" catenateAll="0" />
                <filter class="solr.LowerCaseFilterFactory" />
                <filter class="solr.SnowballPorterFilterFactory" language="English" protected="lang/protwords_en.txt" />
                <!-- this filter can remove any duplicate tokens that appear at the same
                    position - sometimes possible with WordDelimiterFilter in conjuncton with
                    stemming. -->
                <filter class="solr.RemoveDuplicatesTokenFilterFactory" />
            </analyzer>
        </fieldType>


        <!-- A general unstemmed text field - good if one does not know the language
            of the field -->
        <fieldType name="textgen" class="solr.TextField"
            positionIncrementGap="100">
            <analyzer type="index">
                <tokenizer class="solr.WhitespaceTokenizerFactory" />
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1" generateNumberParts="1" catenateWords="1"
                    catenateNumbers="1" catenateAll="0" splitOnCaseChange="0" />
                <filter class="solr.LowerCaseFilterFactory" />
            </analyzer>
            <analyzer type="query">
                <tokenizer class="solr.WhitespaceTokenizerFactory" />
                <!-- best practice (currently) for synonyms is to add them by
                    expansions during index time
                    solr.KeywordTokenizerFactory as tokenizerFactory
                    so synonyms with whitespaces are treated as phrase
                -->
                <filter
                    class="solr.SynonymFilterFactory"
                    synonyms="lang/synonyms_de.txt"
                    ignoreCase="true"
                    expand="true"
                    tokenizerFactory="solr.KeywordTokenizerFactory"
                />
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1" generateNumberParts="1" catenateWords="0"
                    catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" />
                <filter class="solr.LowerCaseFilterFactory" />
            </analyzer>
        </fieldType>


        <!-- A general unstemmed text field that indexes tokens normally and also
            reversed (via ReversedWildcardFilterFactory), to enable more efficient leading
            wildcard queries. -->
        <fieldType name="text_rev" class="solr.TextField"
            positionIncrementGap="100">
            <analyzer type="index">
                <tokenizer class="solr.WhitespaceTokenizerFactory" />
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1" generateNumberParts="1" catenateWords="1"
                    catenateNumbers="1" catenateAll="0" splitOnCaseChange="0" />
                <filter class="solr.LowerCaseFilterFactory" />
                <filter class="solr.ReversedWildcardFilterFactory"
                    withOriginal="true" maxPosAsterisk="3" maxPosQuestion="2"
                    maxFractionAsterisk="0.33" />
            </analyzer>
            <analyzer type="query">
                <tokenizer class="solr.WhitespaceTokenizerFactory" />
                <!-- best practice (currently) for synonyms is to add them by
                    expansions during index time
                    solr.KeywordTokenizerFactory as tokenizerFactory
                    so synonyms with whitespaces are treated as phrase
                -->
                <filter
                    class="solr.SynonymFilterFactory"
                    synonyms="lang/synonyms_de.txt"
                    ignoreCase="true"
                    expand="true"
                    tokenizerFactory="solr.KeywordTokenizerFactory"
                />
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.WordDelimiterFilterFactory"
                    generateWordParts="1" generateNumberParts="1" catenateWords="0"
                    catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" />
                <filter class="solr.LowerCaseFilterFactory" />
            </analyzer>
        </fieldType>

        <!-- charFilter + WhitespaceTokenizer -->
        <!-- <fieldType name="textCharNorm" class="solr.TextField" positionIncrementGap="100"
            > <analyzer> <charFilter class="solr.MappingCharFilterFactory" mapping="mapping-ISOLatin1Accent.txt"/>
            <tokenizer class="solr.WhitespaceTokenizerFactory"/> </analyzer> </fieldType> -->

        <!-- This is an example of using the KeywordTokenizer along With various
            TokenFilterFactories to produce a sortable field that does not include some
            properties of the source text -->
        <fieldType name="alphaOnlySort" class="solr.TextField"
            sortMissingLast="true" omitNorms="true">
            <analyzer>
                <!-- KeywordTokenizer does no actual tokenizing, so the entire input
                    string is preserved as a single token -->
                <tokenizer class="solr.KeywordTokenizerFactory" />
                <!-- The LowerCase TokenFilter does what you expect, which can be when
                    you want your sorting to be case insensitive -->
                <filter class="solr.LowerCaseFilterFactory" />
                <!-- The TrimFilter removes any leading or trailing whitespace -->
                <filter class="solr.TrimFilterFactory" />
                <!-- The PatternReplaceFilter gives you the flexibility to use Java Regular
                    expression to replace any sequence of characters matching a pattern with
                    an arbitrary replacement string, which may include back references to portions
                    of the original string matched by the pattern. See the Java Regular Expression
                    documentation for more information on pattern and replacement string syntax.
                    http://java.sun.com/j2se/1.5.0/docs/api/java/util/regex/package-summary.html -->
                <filter class="solr.PatternReplaceFilterFactory" pattern="([^a-z])"
                    replacement="" replace="all" />
            </analyzer>
        </fieldType>

        <fieldtype name="phonetic" stored="false" indexed="true"
            class="solr.TextField">
            <analyzer>
                <tokenizer class="solr.StandardTokenizerFactory" />
                <filter class="solr.DoubleMetaphoneFilterFactory" inject="false" />
            </analyzer>
        </fieldtype>

        <fieldType name="phoneticGerman" class="solr.TextField" sortMissingLast="true">
            <analyzer type="index">
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.LowerCaseFilterFactory"/>
                <filter class="solr.PhoneticFilterFactory" encoder="ColognePhonetic" inject="false"/>
            </analyzer>
            <analyzer type="query">
                <!--
                    Die Arbeitsweise von ColognePhonetic bringt allerdings ein Problem mit sich:

                    Der Algorithmus wandelt die Zeichen in eine Ziffernfolge um. Die gleiche Ziffernfolge
                    bedeutet gleicher Klang.

                    Sucht man nun z.B. nach 082 (etwa eine Suche nach Telefonnummern o.Ã¤.)
                    findet man alle Solr-Dokumente, die als Eingabe des Fields
                    z.B. den Namen Just, Jost usw. haben. Das ist sicherlich nicht das
                    gewÃ¼nschte Verhalten. Das Problem ist, dass Solr eine Ziffernfolge unverÃ¤ndert Ã¼bernimmt.

                    Durch einen kleinen Trick kann man diesen Umstand aber umgehen:
                    <charFilter class="solr.PatternReplaceCharFilterFactory" pattern="^(.*)$" replacement="$1#"/>

                    Man hÃ¤ngt wÃ¤hrend der Suchanalyse ein # an das Ende des Suchbegriffs.
                    Dieses Sonderzeichen bewirkt, dass passende alphanummerische Suchbegriffe
                    gefunden werden, aber nummerische Suchbegriffe nicht mehr. D.h. eine Suche
                    nach Jost findet auch Just, eine Suche nach 082 findet Just hingegen nicht mehr.
                 -->
                <tokenizer class="solr.WhitespaceTokenizerFactory"/>
                <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" />
                <filter class="solr.LowerCaseFilterFactory"/>
                <filter class="solr.PhoneticFilterFactory" encoder="ColognePhonetic" inject="false"/>
            </analyzer>
        </fieldType>

        <fieldtype name="payloads" stored="false" indexed="true"
            class="solr.TextField">
            <analyzer>
                <tokenizer class="solr.WhitespaceTokenizerFactory" />
                <!-- The DelimitedPayloadTokenFilter can put payloads on tokens... for
                    example, a token of "foo|1.4" would be indexed as "foo" with a payload of
                    1.4f Attributes of the DelimitedPayloadTokenFilterFactory : "delimiter" -
                    a one character delimiter. Default is | (pipe) "encoder" - how to encode
                    the following value into a playload float -> org.apache.lucene.analysis.payloads.FloatEncoder,
                    integer -> o.a.l.a.p.IntegerEncoder identity -> o.a.l.a.p.IdentityEncoder
                    Fully Qualified class name implementing PayloadEncoder, Encoder must have
                    a no arg constructor. -->
                <filter class="solr.DelimitedPayloadTokenFilterFactory"
                    encoder="float" />
            </analyzer>
        </fieldtype>

        <!-- lowercases the entire field value, keeping it as a single token. -->
        <fieldType name="lowercase" class="solr.TextField"
            positionIncrementGap="100">
            <analyzer>
                <tokenizer class="solr.KeywordTokenizerFactory" />
                <filter class="solr.LowerCaseFilterFactory" />
            </analyzer>
        </fieldType>

        <!-- suggesting single words and phrases up to 4 words in german language -->
        <fieldType class="solr.TextField" name="text_autocomplete" positionIncrementGap="100">
            <analyzer type="index">
                <tokenizer class="solr.StandardTokenizerFactory" />
                <filter class="solr.LowerCaseFilterFactory" />
                <!-- only alpha num and whitespaces -->
                <filter class="solr.PatternReplaceFilterFactory" pattern="([^a-zÃ¤Ã¶Ã¼ÃÃÃÃ0-9 ])"
                    replacement="" replace="all" />
                    <!--
                        build groups of words to support phrases.
                        if we don't do this, we get the complete text after the hit.
                        in some cases this text can be too long.
                        imagine you index the text "the quick brown fox jumps over the lazy frog"
                        and search for "the quick". without the shingle filter we would get as result
                        "the quick brown fox jumps over the lazy frog" and with the shingle filter we would get
                        "the quick brown fox".
                    -->
                <filter class="solr.ShingleFilterFactory" maxShingleSize="4" outputUnigrams="true" />
                <filter class="solr.TrimFilterFactory" />
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
            <analyzer type="query">
                <tokenizer class="solr.StandardTokenizerFactory" />
                <filter class="solr.LowerCaseFilterFactory"/>
                <filter class="solr.TrimFilterFactory" />
                <!-- only alpha num and whitespaces -->
                <filter class="solr.PatternReplaceFilterFactory" pattern="([^a-zÃ¤Ã¶Ã¼ÃÃÃÃ0-9 ])"
                    replacement="" replace="all" />
                <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
            </analyzer>
        </fieldType>

        <fieldType
            name="text_sort"
            class="solr.CollationField"
            language=""
            strength="primary"
        />

        <!-- since fields of this type are by default not stored or indexed, any
            data added to them will be ignored outright. -->
        <fieldtype name="ignored" stored="false" indexed="false"
            multiValued="true" class="solr.StrField" />

    </types>


    <fields>
        <!-- Valid attributes for fields: name: mandatory - the name for the field
            type: mandatory - the name of a previously defined type from the <types>
            section indexed: true if this field should be indexed (searchable or sortable)
            stored: true if this field should be retrievable compressed: [false] if this
            field should be stored using gzip compression (this will only apply if the
            field type is compressable; among the standard field types, only TextField
            and StrField are) multiValued: true if this field may contain multiple values
            per document omitNorms: (expert) set to true to omit the norms associated
            with this field (this disables length normalization and index-time boosting
            for the field, and saves some memory). Only full-text fields or fields that
            need an index-time boost need norms. termVectors: [false] set to true to
            store the term vector for a given field. When using MoreLikeThis, fields
            used for similarity should be stored for best performance. termPositions:
            Store position information with the term vector. This will increase storage
            costs. termOffsets: Store offset information with the term vector. This will
            increase storage costs. default: a value that should be used if no value
            is specified when adding a document. -->

        <field name="id" type="string" indexed="true" stored="true" required="true" />

        <!--
            It is used internally by Solr, for example by features like partial
            update functionality and update log.
         -->
        <field name="_version_" type="long" indexed="true" stored="true"/>

        <!-- common mksearch fields -->
        <field name="extKey" type="string" indexed="true" stored="true" required="false" />
        <field name="uid" type="int" indexed="true" stored="true" required="false" />
        <field name="contentType" type="string" indexed="true" stored="true" required="true" />
        <field name="tstamp" type="int" indexed="true" stored="true" />
        <field name="siteRootPage" type="int" indexed="true" stored="true" />

        <field name="subject" type="text_german" indexed="true" stored="true" />
        <field name="description" type="text_german" indexed="true" stored="true" />
        <field name="comments" type="text_german" indexed="true" stored="true" />
        <field name="author" type="textgen" indexed="true" stored="true" />
        <field name="keywords" type="textgen" indexed="true" stored="true" />
        <field name="category" type="textgen" indexed="true" stored="true" />
        <field name="content_type" type="strings" indexed="true" stored="true" multiValued="true" />
        <field name="last_modified" type="date" indexed="true" stored="true" />
        <field name="links" type="strings" indexed="true" stored="true" multiValued="true" />

        <!-- catchall text field that indexes tokens both normally and in reverse
            for efficient leading wildcard queries. -->
        <field name="text_rev" type="text_rev" indexed="true" stored="false" multiValued="true" />

        <!-- Uncommenting the following will create a "timestamp" field using a
            default value of "NOW" to indicate when each document was indexed. -->
        <field name="timestamp" type="date" indexed="true" stored="true" default="NOW" multiValued="false" />

        <!-- common TYPO3 fields -->
        <field name="deleted" type="int" indexed="true" stored="true" />
        <field name="hidden" type="int" indexed="true" stored="true" />
        <field name="fe_groups" type="int" indexed="true" stored="false" />
        <field name="pid" type="int" indexed="true" stored="true" />
        <field name="CType" type="string" indexed="true" stored="true" />
        <field name="abstract" type="text_german" indexed="true" stored="true" />

        <field name="datetime" type="date" indexed="true" stored="true" />

        <!--  searchable fields in de and en -->
        <field name="title" type="text" indexed="true" stored="true" multiValued="false" />

        <!--  make title sortable -->
        <field name="title_sort" type="text_sort" indexed="true" stored="false" multiValued="false" />
         <copyField source="title" dest="title_sort" />

        <field name="content" type="text" indexed="true" stored="true" />

        <field name="fulltext" type="text" indexed="true" stored="false" multiValued="true" />

        <!-- create and copy language fields -->
        <field name="title_german" type="text_german" indexed="true" stored="false" multiValued="false" />
        <field name="title_english" type="text_english" indexed="true" stored="false" multiValued="false" />
        <copyField source="title" dest="title_german" />
        <copyField source="title" dest="title_english" />

        <field name="content_german" type="text_german" indexed="true" stored="false" multiValued="true" />
        <field name="content_english" type="text_english" indexed="true" stored="false" multiValued="true" />
        <copyField source="content" dest="content_german" />
        <copyField source="content" dest="content_english" />

        <field name="fulltext_german" type="full_text_german" indexed="true" stored="false" multiValued="true" />
        <field name="fulltext_english" type="full_text_english" indexed="true" stored="false" multiValued="true" />
        <copyField source="fulltext" dest="fulltext_german" />
        <copyField source="fulltext" dest="fulltext_english" />

        <!-- some copy fields for fulltext search -->

        <copyField source="*_t" dest="fulltext_german"/>
        <copyField source="*_t" dest="fulltext_english"/>
        <copyField source="*_mt" dest="fulltext_german"/>
        <copyField source="*_mt" dest="fulltext_english"/>

        <!-- Autocomplete. copy all fields to "text_autocomplete_phrases" which should be used
            for a autocomplete search -->
        <field name="text_autocomplete_phrases" type="text_autocomplete" indexed="true" stored="false" multiValued="true" />
        <copyField source="title" dest="text_autocomplete_phrases" />
        <copyField source="mkkeywords_tag_names_ms" dest="text_autocomplete_phrases" />

        <!-- Dynamic field definitions. If a field name is not found, dynamicFields
            will be used if the name matches any of the patterns. RESTRICTION: the glob-like
            pattern in the name attribute must have a "*" only at the start or the end.
            EXAMPLE: name="*_i" will match any field ending in _i (like myid_i, z_i)
            Longer patterns will be matched first. if equal size patterns both match,
            the first appearing in the schema will be used. -->
        <dynamicField name="*_i" type="int" indexed="true" stored="true" />
        <!--
            highlighting for (dynamic) string fields will not work.
            in this case the type *_s should not be string but text. this should
            be fine.
            If parts of a word should be highlighted the field type
            must contain some sort of ngram filter.
         -->
         <!--
            many extensions use the *_s field as text field and not as string field. that's why the
            default type is text_german so highlighting on these fields works at all and supports stemming etc.
         -->
        <dynamicField name="*_s" type="string_ci" indexed="true" stored="true" />
        <dynamicField name="*_l" type="long" indexed="true" stored="true" />
        <dynamicField name="*_t" type="text_german" indexed="true" stored="true" />
        <dynamicField name="*_b" type="boolean" indexed="true" stored="true" />
        <dynamicField name="*_f" type="float" indexed="true" stored="true" />
        <dynamicField name="*_d" type="double" indexed="true" stored="true" />
        <dynamicField name="*_dt" type="date" indexed="true" stored="true" />

        <dynamicField name="*_mi" type="int" indexed="true" stored="true" multiValued="true" />
        <dynamicField name="*_ms" type="strings_ci" indexed="true" stored="true" multiValued="true" />
        <dynamicField name="*_ml" type="long" indexed="true" stored="true" multiValued="true" />
        <dynamicField name="*_mt" type="text_german" indexed="true" stored="true" multiValued="true" />
        <dynamicField name="*_mb" type="boolean" indexed="true" stored="true" multiValued="true" />
        <dynamicField name="*_mf" type="float" indexed="true" stored="true" multiValued="true" />
        <dynamicField name="*_md" type="double" indexed="true" stored="true" multiValued="true" />
        <dynamicField name="*_mdt" type="date" indexed="true" stored="true" multiValued="true" />

        <!-- some trie-coded dynamic fields for faster range queries -->
        <dynamicField name="*_ti" type="tint" indexed="true" stored="true" />
        <dynamicField name="*_tl" type="tlong" indexed="true" stored="true" />
        <dynamicField name="*_tf" type="tfloat" indexed="true" stored="true" />
        <dynamicField name="*_td" type="tdouble" indexed="true" stored="true" />
        <dynamicField name="*_tdt" type="tdate" indexed="true" stored="true" />

        <!--
            For Geospatial search
         -->
        <dynamicField name="*_latlon" type="location" indexed="true" stored="false" />
        <dynamicField name="*_coord" type="tdouble" indexed="true" stored="false" />

        <dynamicField name="ignored_*" type="ignored" multiValued="true" />
        <dynamicField name="attr_*" type="textgen" indexed="true" stored="true" multiValued="true" />

        <dynamicField name="random_*" type="random" />

        <!-- uncomment the following to ignore any fields that don't already match
            an existing field name or dynamic field, rather than reporting them as an
            error. alternately, change the type="ignored" to some other type e.g. "text"
            if you want unknown fields indexed and/or stored by default -->
        <!--dynamicField name="*" type="ignored" multiValued="true" / -->

        <!-- Cal Event -->
           <!-- <copyField source="organizer_s" dest="fulltext"/>
           <copyField source="organizer_link_s" dest="fulltext"/>
           <copyField source="location_s" dest="fulltext"/>
           <copyField source="description_s" dest="fulltext"/>
           <copyField source="calendar_title_s" dest="fulltext"/>
           <copyField source="category_title_ms" dest="fulltext"/> -->

           <!-- News -->
           <!-- <copyField source="news_text_s" dest="fulltext"/> -->
           <!-- <copyField source="categoriesTitle_ms" dest="fulltext"/> -->
        <!-- <copyField source="short_t" dest="fulltext"/> -->
        <!-- <copyField source="keywords_s" dest="fulltext"/> -->
        <!-- <copyField source="author_s" dest="fulltext"/> -->

           <!-- irfaq -->
           <!-- <copyField source="q_s" dest="fulltext"/>
           <copyField source="a_s" dest="fulltext"/>
           <copyField source="related_s" dest="fulltext"/>
           <copyField source="related_links_s" dest="fulltext"/>
           <copyField source="expert_name_s" dest="fulltext"/>
           <copyField source="category_title_ms" dest="fulltext"/> -->

    </fields>

    <!-- Field to use to determine and enforce document uniqueness. Unless this
        field is marked with required="false", it will be a required field -->
    <uniqueKey>id</uniqueKey>

    <!-- copyField commands copy one field to another at the time a document
        is added to the index. It's used either to index the same field differently,
        or to add multiple fields to the same field for easier/faster searching. -->

    <!-- Above, multiple source fields are copied to the [text] field. Another
        way to map multiple source fields to the same destination field is to use
        the dynamic field syntax. copyField also supports a maxChars to copy setting. -->

    <!-- <copyField source="*_t" dest="fulltext" maxChars="3000"/> -->

    <!-- copy name to alphaNameSort, a field designed for sorting by name -->
    <!-- <copyField source="name" dest="alphaNameSort"/> -->


    <!-- Similarity is the scoring routine for each document vs. a query. A
        custom similarity may be specified here, but the default is fine for most
        applications. -->
    <!-- <similarity class="org.apache.lucene.search.DefaultSimilarity"/> -->
    <!-- ... OR ... Specify a SimilarityFactory class name implementation allowing
        parameters to be used. -->
    <!-- <similarity class="com.example.solr.CustomSimilarityFactory"> <str
        name="paramkey">param value</str> </similarity> -->


</schema>
